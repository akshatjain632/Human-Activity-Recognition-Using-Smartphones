{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AiOCrurtBiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd015566-bca6-43f7-ed98-54dd1af683f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers, callbacks\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from subprocess import call\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "INPUT_SIGNAL_TYPES = [\n",
        "    \"body_acc_x_\", \"body_acc_y_\", \"body_acc_z_\",\n",
        "    \"body_gyro_x_\", \"body_gyro_y_\", \"body_gyro_z_\",\n",
        "    \"total_acc_x_\", \"total_acc_y_\", \"total_acc_z_\"\n",
        "]\n",
        "LABELS = [\"WALKING\", \"WALKING_UPSTAIRS\", \"WALKING_DOWNSTAIRS\",\n",
        "          \"SITTING\", \"STANDING\", \"LAYING\"]\n"
      ],
      "metadata": {
        "id": "KHCNBo1Gt8VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"UCI HAR Dataset.zip\"):\n",
        "    call(\n",
        "        'wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI HAR Dataset.zip\"',\n",
        "        shell=True\n",
        "    )\n",
        "    print(\"Downloading done.\\n\")\n",
        "else:\n",
        "    print(\"Dataset already downloaded. Skipping.\\n\")\n",
        "\n",
        "extract_directory = os.path.abspath(\"UCI HAR Dataset\")\n",
        "if not os.path.exists(extract_directory):\n",
        "    call(\n",
        "        'unzip -nq \"UCI HAR Dataset.zip\"',\n",
        "        shell=True\n",
        "    )\n",
        "    print(f\"Extracted to {extract_directory}.\\n\")\n",
        "else:\n",
        "    print(\"Dataset already extracted. Skipping.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ57_qcQt9Jw",
        "outputId": "7c39930f-e50c-41fb-acf4-1258849388cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading done.\n",
            "\n",
            "Extracted to /content/UCI HAR Dataset.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = \"UCI HAR Dataset/train/\"\n",
        "TEST  = \"UCI HAR Dataset/test/\"\n",
        "\n",
        "def load_X(paths):\n",
        "    X_signals = []\n",
        "    for p in paths:\n",
        "        with open(p, 'r') as f:\n",
        "            series = [np.array(row.strip().split(), dtype=np.float32)\n",
        "                      for row in f]\n",
        "            X_signals.append(np.array(series))\n",
        "    # shape -> (n_examples, signal_length, n_signals)\n",
        "    return np.stack(X_signals, axis=-1)\n",
        "\n",
        "def load_y(path):\n",
        "    with open(path, 'r') as f:\n",
        "        y_ = np.array([int(r.strip()) for r in f], dtype=np.int32)\n",
        "    return y_ - 1\n",
        "\n",
        "signal_files = INPUT_SIGNAL_TYPES\n",
        "X_train_paths = [os.path.join(TRAIN, \"Inertial Signals\", f + \"train.txt\")\n",
        "                 for f in signal_files]\n",
        "X_test_paths  = [os.path.join(TEST, \"Inertial Signals\", f + \"test.txt\")\n",
        "                 for f in signal_files]\n",
        "\n",
        "X_train = load_X(X_train_paths)\n",
        "X_test  = load_X(X_test_paths)\n",
        "y_train = load_y(os.path.join(TRAIN, \"y_train.txt\"))\n",
        "y_test  = load_y(os.path.join(TEST, \"y_test.txt\"))\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMW-xk69t-BW",
        "outputId": "1bce5e0b-5ff4-44bb-83d7-f6b97b01fd3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (7352, 128, 9)\n",
            "y_train shape: (7352,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine Annealing function\n",
        "def cosine_annealing(epoch):\n",
        "    min_lr = 1e-6\n",
        "    return min_lr + (learning_rate - min_lr) * (1 + math.cos(math.pi * epoch / epochs)) / 2"
      ],
      "metadata": {
        "id": "ho-tErffA5yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters-Common for all models\n",
        "n_steps = X_train.shape[1]\n",
        "n_input = X_train.shape[2]\n",
        "n_classes = len(LABELS)\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "learning_rate = 0.0025\n",
        "lambda_loss_amount = 0.0015\n",
        "dropout_rate = 0.2"
      ],
      "metadata": {
        "id": "fM1p1rA2t_BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode\n",
        "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=n_classes)\n",
        "y_test_cat  = tf.keras.utils.to_categorical(y_test,  num_classes=n_classes)"
      ],
      "metadata": {
        "id": "IMLRF4Jkt_2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare datasets\n",
        "train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((X_train, y_train_cat))\n",
        "    .cache()\n",
        "    .shuffle(5000)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "test_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((X_test, y_test_cat))\n",
        "    .batch(batch_size)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "2IhUk2lTqpJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cb_early = callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "cb_lr = callbacks.LearningRateScheduler(cosine_annealing, verbose=1)\n",
        "cb_reduce = callbacks.ReduceLROnPlateau(factor=0.5, patience=2, min_lr=1e-6)"
      ],
      "metadata": {
        "id": "vBb27eV6uDO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4KYWfXJLrqUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z0xYPSeTrqJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN-1:2 layers of Simple RNN with dropout after every layer, Adam optimizer, categorical cross entropy loss, Callback using Early stopping and Reduce LR on Plateau"
      ],
      "metadata": {
        "id": "EKfGRDIVrqFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(n_steps, n_input))\n",
        "x = layers.SimpleRNN(128,return_sequences=True,kernel_regularizer=regularizers.l2(lambda_loss_amount))(inputs)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.SimpleRNN(64,kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "logits = layers.Dense(n_classes,kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "rnn_model_1 = models.Model(inputs, logits)\n",
        "rnn_model_1.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy')],\n",
        "    jit_compile=True\n",
        ")\n",
        "rnn_model_1.summary()\n",
        "history = rnn_model_1.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_ds,\n",
        "    callbacks=[cb_early,cb_reduce]\n",
        ")\n",
        "loss, acc = rnn_model_1.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
        "y_proba = rnn_model_1.predict(test_ds)\n",
        "rnn_1_y_pred = np.argmax(y_proba, axis=1)\n",
        "y_true = y_test\n",
        "print(metrics.classification_report(\n",
        "    y_true, rnn_1_y_pred, target_names=LABELS, digits=4, zero_division=0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-B480BAwrrRW",
        "outputId": "7cb1281a-7b00-464f-8313-64ca2d993339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m17,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m12,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,406\u001b[0m (118.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,406</span> (118.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,406\u001b[0m (118.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,406</span> (118.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 550ms/step - accuracy: 0.4602 - loss: 1.4509 - val_accuracy: 0.5931 - val_loss: 1.1422 - learning_rate: 0.0025\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 534ms/step - accuracy: 0.6407 - loss: 0.9275 - val_accuracy: 0.6644 - val_loss: 1.0386 - learning_rate: 0.0025\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 516ms/step - accuracy: 0.6900 - loss: 0.8387 - val_accuracy: 0.5517 - val_loss: 1.1857 - learning_rate: 0.0025\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 518ms/step - accuracy: 0.6548 - loss: 0.9346 - val_accuracy: 0.6956 - val_loss: 0.8253 - learning_rate: 0.0025\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 511ms/step - accuracy: 0.7178 - loss: 0.7689 - val_accuracy: 0.5738 - val_loss: 1.2423 - learning_rate: 0.0025\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 511ms/step - accuracy: 0.5759 - loss: 1.0963 - val_accuracy: 0.6081 - val_loss: 1.0424 - learning_rate: 0.0025\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 513ms/step - accuracy: 0.6374 - loss: 0.8718 - val_accuracy: 0.6899 - val_loss: 0.8216 - learning_rate: 0.0012\n",
            "Epoch 8/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 496ms/step - accuracy: 0.6822 - loss: 0.8587 - val_accuracy: 0.6563 - val_loss: 0.8650 - learning_rate: 0.0012\n",
            "Epoch 9/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 504ms/step - accuracy: 0.7162 - loss: 0.7375 - val_accuracy: 0.7187 - val_loss: 0.7774 - learning_rate: 0.0012\n",
            "Epoch 10/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 502ms/step - accuracy: 0.7460 - loss: 0.7052 - val_accuracy: 0.7194 - val_loss: 0.8092 - learning_rate: 0.0012\n",
            "Epoch 11/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 564ms/step - accuracy: 0.7618 - loss: 0.7051 - val_accuracy: 0.6301 - val_loss: 0.9741 - learning_rate: 0.0012\n",
            "Epoch 12/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 550ms/step - accuracy: 0.6843 - loss: 0.8428 - val_accuracy: 0.6888 - val_loss: 0.8459 - learning_rate: 6.2500e-04\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7251 - loss: 0.8025\n",
            "Test Loss: 0.7774, Test Accuracy: 0.7187\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "           WALKING     0.4943    0.7903    0.6082       496\n",
            "  WALKING_UPSTAIRS     0.6752    0.1677    0.2687       471\n",
            "WALKING_DOWNSTAIRS     0.6213    0.7500    0.6796       420\n",
            "           SITTING     0.9277    0.6008    0.7293       491\n",
            "          STANDING     0.7415    0.9436    0.8304       532\n",
            "            LAYING     1.0000    0.9963    0.9981       537\n",
            "\n",
            "          accuracy                         0.7187      2947\n",
            "         macro avg     0.7433    0.7081    0.6857      2947\n",
            "      weighted avg     0.7503    0.7187    0.6955      2947\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WWXDTCyTvbzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXCqXGGdyAX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN-2: Building up on RNN-1, this model has Layer normalization after every RNN layer, and implements Cosine Annealing instead of Reduce LR on Plateau"
      ],
      "metadata": {
        "id": "vSvOCeE-vbqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(n_steps, n_input))\n",
        "x = layers.SimpleRNN(128,return_sequences=True,kernel_regularizer=regularizers.l2(lambda_loss_amount))(inputs)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.SimpleRNN(64,kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "logits = layers.Dense(n_classes,kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "rnn_model_2 = models.Model(inputs, logits)\n",
        "rnn_model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy')],\n",
        "    jit_compile=True\n",
        ")\n",
        "rnn_model_2.summary()\n",
        "history = rnn_model_2.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_ds,\n",
        "    callbacks=[cb_early,cb_lr]\n",
        ")\n",
        "loss, acc = rnn_model_2.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
        "y_proba = rnn_model_2.predict(test_ds)\n",
        "rnn_2_y_pred  = np.argmax(y_proba, axis=1)\n",
        "y_true  = y_test\n",
        "print(metrics.classification_report(\n",
        "    y_true, rnn_2_y_pred, target_names=LABELS, digits=4, zero_division=0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j7hYFXD8v570",
        "outputId": "f589fd0f-b7ce-4ff8-af56-a550308c2500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m17,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_3 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m12,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,790\u001b[0m (120.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,790</span> (120.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,790\u001b[0m (120.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,790</span> (120.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0025.\n",
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 620ms/step - accuracy: 0.3883 - loss: 1.7552 - val_accuracy: 0.5925 - val_loss: 1.1710 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0024975343971711255.\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 557ms/step - accuracy: 0.5887 - loss: 1.1150 - val_accuracy: 0.6464 - val_loss: 0.9882 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0024901473192924404.\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 545ms/step - accuracy: 0.5476 - loss: 1.2028 - val_accuracy: 0.5697 - val_loss: 1.1949 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.002477867919785497.\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 564ms/step - accuracy: 0.6054 - loss: 1.0457 - val_accuracy: 0.6522 - val_loss: 0.9460 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0024607446598302247.\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 548ms/step - accuracy: 0.6085 - loss: 1.0317 - val_accuracy: 0.5314 - val_loss: 1.3242 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0024388451171107944.\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 563ms/step - accuracy: 0.5928 - loss: 1.0954 - val_accuracy: 0.3702 - val_loss: 1.4911 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00241225571911737.\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 554ms/step - accuracy: 0.4560 - loss: 1.4206 - val_accuracy: 0.4910 - val_loss: 1.4268 - learning_rate: 0.0024\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6242 - loss: 1.0514\n",
            "Test Loss: 0.9460, Test Accuracy: 0.6522\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "           WALKING     0.4052    0.6593    0.5019       496\n",
            "  WALKING_UPSTAIRS     0.5845    0.3524    0.4397       471\n",
            "WALKING_DOWNSTAIRS     0.4635    0.4690    0.4663       420\n",
            "           SITTING     0.8329    0.6904    0.7550       491\n",
            "          STANDING     0.7446    0.7180    0.7311       532\n",
            "            LAYING     1.0000    0.9516    0.9752       537\n",
            "\n",
            "          accuracy                         0.6522      2947\n",
            "         macro avg     0.6718    0.6401    0.6449      2947\n",
            "      weighted avg     0.6831    0.6522    0.6567      2947\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1Syh_Uhxw_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ezr7KS6uxw2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN-3: Builds on the previous RNN-2 model, adding a 3rd layer of the RNN model, adding gaussian noise to the inputs of the model, and capping the L2 norm of gradients during ADAM optimization to 1.0"
      ],
      "metadata": {
        "id": "57Rd0iiIyDBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(n_steps, n_input))\n",
        "x = layers.GaussianNoise(0.1)(inputs)\n",
        "x = layers.SimpleRNN(128,return_sequences=True,kernel_regularizer=regularizers.l2(lambda_loss_amount),recurrent_dropout=0.2)(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.SimpleRNN(64,return_sequences=True,kernel_regularizer=regularizers.l2(lambda_loss_amount),recurrent_dropout=0.2)(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.SimpleRNN(32,kernel_regularizer=regularizers.l2(lambda_loss_amount),recurrent_dropout=0.2)(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "logits = layers.Dense(n_classes,kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "rnn_model_3 = models.Model(inputs, logits)\n",
        "rnn_model_3.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,clipnorm=1.0),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy')],\n",
        "    jit_compile=True\n",
        ")\n",
        "rnn_model_3.summary()\n",
        "history = rnn_model_3.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_ds,\n",
        "    callbacks=[cb_early,cb_lr]\n",
        ")\n",
        "loss, acc = rnn_model_3.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
        "y_proba = rnn_model_3.predict(test_ds)\n",
        "rnn_3_y_pred  = np.argmax(y_proba, axis=1)\n",
        "y_true  = y_test\n",
        "print(metrics.classification_report(\n",
        "    y_true, rnn_3_y_pred, target_names=LABELS, digits=4, zero_division=0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uoLv1p38zQw6",
        "outputId": "60a52d4b-c3ed-4736-daa3-1d6e61595bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gaussian_noise (\u001b[38;5;33mGaussianNoise\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_4 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m17,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_5 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m12,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_6 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m3,104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gaussian_noise (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,766\u001b[0m (131.90 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,766</span> (131.90 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,766\u001b[0m (131.90 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,766</span> (131.90 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0025.\n",
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 826ms/step - accuracy: 0.2735 - loss: 2.1719 - val_accuracy: 0.3359 - val_loss: 1.6499 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0024975343971711255.\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 700ms/step - accuracy: 0.3399 - loss: 1.6980 - val_accuracy: 0.4398 - val_loss: 1.5826 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0024901473192924404.\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 683ms/step - accuracy: 0.3616 - loss: 1.6304 - val_accuracy: 0.3773 - val_loss: 1.5574 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.002477867919785497.\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 701ms/step - accuracy: 0.3755 - loss: 1.5753 - val_accuracy: 0.3879 - val_loss: 1.5715 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0024607446598302247.\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 712ms/step - accuracy: 0.4100 - loss: 1.4867 - val_accuracy: 0.4340 - val_loss: 1.4336 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0024388451171107944.\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 699ms/step - accuracy: 0.4329 - loss: 1.4246 - val_accuracy: 0.3916 - val_loss: 1.4895 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00241225571911737.\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 691ms/step - accuracy: 0.3923 - loss: 1.4944 - val_accuracy: 0.3875 - val_loss: 1.4990 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0023810814020562916.\n",
            "Epoch 8/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 699ms/step - accuracy: 0.4059 - loss: 1.4356 - val_accuracy: 0.3566 - val_loss: 1.5167 - learning_rate: 0.0024\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.4091 - loss: 1.4720\n",
            "Test Loss: 1.4336, Test Accuracy: 0.4340\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "           WALKING     0.2500    0.0020    0.0040       496\n",
            "  WALKING_UPSTAIRS     0.2527    0.9384    0.3982       471\n",
            "WALKING_DOWNSTAIRS     0.0000    0.0000    0.0000       420\n",
            "           SITTING     0.6746    0.6334    0.6534       491\n",
            "          STANDING     0.1476    0.0583    0.0836       532\n",
            "            LAYING     0.9446    0.9199    0.9321       537\n",
            "\n",
            "          accuracy                         0.4340      2947\n",
            "         macro avg     0.3783    0.4253    0.3452      2947\n",
            "      weighted avg     0.3936    0.4340    0.3581      2947\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LiJCyolrzzX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K9lWbD_-zzK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU-1: GRU Model with the same structure and characteristics as RNN-1 model"
      ],
      "metadata": {
        "id": "w8pM29BEzzAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(n_steps, n_input))\n",
        "x = layers.GRU(128,return_sequences=True,kernel_regularizer=regularizers.l2(lambda_loss_amount))(inputs)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.GRU(64,kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "logits = layers.Dense(n_classes,kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "gru_model_1 = models.Model(inputs, logits)\n",
        "gru_model_1.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy')],\n",
        "    jit_compile=True\n",
        ")\n",
        "gru_model_1.summary()\n",
        "history = gru_model_1.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_ds,\n",
        "    callbacks=[cb_early, cb_reduce]\n",
        ")\n",
        "loss, acc = gru_model_1.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
        "y_proba = gru_model_1.predict(test_ds)\n",
        "gru_1_y_pred  = np.argmax(y_proba, axis=1)\n",
        "y_true  = y_test\n",
        "print(metrics.classification_report(\n",
        "    y_true, gru_1_y_pred, target_names=LABELS, digits=4, zero_division=0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jw5EVnXC2l8H",
        "outputId": "d73f2922-ace3-427b-b32b-278950a3006f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m53,376\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m37,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,376</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91,014\u001b[0m (355.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,014</span> (355.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91,014\u001b[0m (355.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,014</span> (355.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 926ms/step - accuracy: 0.4199 - loss: 1.5375 - val_accuracy: 0.5059 - val_loss: 1.2358 - learning_rate: 0.0025\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 977ms/step - accuracy: 0.6707 - loss: 0.8797 - val_accuracy: 0.8493 - val_loss: 0.5289 - learning_rate: 0.0025\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 883ms/step - accuracy: 0.9061 - loss: 0.3518 - val_accuracy: 0.9013 - val_loss: 0.4169 - learning_rate: 0.0025\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 920ms/step - accuracy: 0.9385 - loss: 0.2455 - val_accuracy: 0.8873 - val_loss: 0.4176 - learning_rate: 0.0025\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 954ms/step - accuracy: 0.9375 - loss: 0.2370 - val_accuracy: 0.8955 - val_loss: 0.4146 - learning_rate: 0.0025\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 902ms/step - accuracy: 0.9429 - loss: 0.1997 - val_accuracy: 0.8829 - val_loss: 0.4516 - learning_rate: 0.0025\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 954ms/step - accuracy: 0.9457 - loss: 0.1989 - val_accuracy: 0.8948 - val_loss: 0.3484 - learning_rate: 0.0025\n",
            "Epoch 8/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 908ms/step - accuracy: 0.9420 - loss: 0.1935 - val_accuracy: 0.8887 - val_loss: 0.3787 - learning_rate: 0.0025\n",
            "Epoch 9/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 897ms/step - accuracy: 0.9393 - loss: 0.2376 - val_accuracy: 0.8894 - val_loss: 0.3947 - learning_rate: 0.0025\n",
            "Epoch 10/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 901ms/step - accuracy: 0.9474 - loss: 0.1965 - val_accuracy: 0.8948 - val_loss: 0.3417 - learning_rate: 0.0012\n",
            "Epoch 11/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 917ms/step - accuracy: 0.9428 - loss: 0.1911 - val_accuracy: 0.8975 - val_loss: 0.3552 - learning_rate: 0.0012\n",
            "Epoch 12/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 885ms/step - accuracy: 0.9560 - loss: 0.1653 - val_accuracy: 0.8972 - val_loss: 0.3663 - learning_rate: 0.0012\n",
            "Epoch 13/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 905ms/step - accuracy: 0.9560 - loss: 0.1650 - val_accuracy: 0.9006 - val_loss: 0.3823 - learning_rate: 6.2500e-04\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.8754 - loss: 0.3940\n",
            "Test Loss: 0.3417, Test Accuracy: 0.8948\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "           WALKING     0.9701    0.9153    0.9419       496\n",
            "  WALKING_UPSTAIRS     0.8978    0.9512    0.9237       471\n",
            "WALKING_DOWNSTAIRS     0.9185    0.9929    0.9542       420\n",
            "           SITTING     0.8873    0.6415    0.7447       491\n",
            "          STANDING     0.7427    0.9117    0.8186       532\n",
            "            LAYING     1.0000    0.9646    0.9820       537\n",
            "\n",
            "          accuracy                         0.8948      2947\n",
            "         macro avg     0.9027    0.8962    0.8942      2947\n",
            "      weighted avg     0.9018    0.8948    0.8929      2947\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZFwPfa5928VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oZ9rweX228Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU-2: GRU version of RNN-2"
      ],
      "metadata": {
        "id": "kCz4Z12f29Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(n_steps, n_input))\n",
        "x = layers.GRU(128,return_sequences=True,kernel_regularizer=regularizers.l2(lambda_loss_amount))(inputs)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.GRU(64,kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "logits = layers.Dense(n_classes,kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "gru_model_2 = models.Model(inputs, logits)\n",
        "gru_model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy')],\n",
        "    jit_compile=True\n",
        ")\n",
        "gru_model_2.summary()\n",
        "history = gru_model_2.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_ds,\n",
        "    callbacks=[cb_early, cb_lr]\n",
        ")\n",
        "loss, acc = gru_model_2.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
        "y_proba = gru_model_2.predict(test_ds)\n",
        "gru_2_y_pred  = np.argmax(y_proba, axis=1)\n",
        "y_true  = y_test\n",
        "print(metrics.classification_report(\n",
        "    y_true, gru_2_y_pred, target_names=LABELS, digits=4, zero_division=0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wmNM3Ggn3DKH",
        "outputId": "60e8312f-c9b4-4670-8933-72aa4445b5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m53,376\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m37,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,376</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91,398\u001b[0m (357.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,398</span> (357.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91,398\u001b[0m (357.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,398</span> (357.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0025.\n",
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.5298 - loss: 1.5581 - val_accuracy: 0.8344 - val_loss: 0.6519 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0024975343971711255.\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 954ms/step - accuracy: 0.8931 - loss: 0.4788 - val_accuracy: 0.8965 - val_loss: 0.4615 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0024901473192924404.\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 934ms/step - accuracy: 0.9356 - loss: 0.3234 - val_accuracy: 0.8931 - val_loss: 0.3902 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.002477867919785497.\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 933ms/step - accuracy: 0.9485 - loss: 0.2547 - val_accuracy: 0.9175 - val_loss: 0.3447 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0024607446598302247.\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 989ms/step - accuracy: 0.9514 - loss: 0.2136 - val_accuracy: 0.9131 - val_loss: 0.3116 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0024388451171107944.\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 932ms/step - accuracy: 0.9450 - loss: 0.2240 - val_accuracy: 0.9087 - val_loss: 0.3367 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00241225571911737.\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 926ms/step - accuracy: 0.9523 - loss: 0.1995 - val_accuracy: 0.9192 - val_loss: 0.3319 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0023810814020562916.\n",
            "Epoch 8/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 938ms/step - accuracy: 0.9464 - loss: 0.2017 - val_accuracy: 0.9009 - val_loss: 0.3235 - learning_rate: 0.0024\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.8785 - loss: 0.3645\n",
            "Test Loss: 0.3116, Test Accuracy: 0.9131\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "           WALKING     0.9873    0.9435    0.9649       496\n",
            "  WALKING_UPSTAIRS     0.9761    0.9533    0.9646       471\n",
            "WALKING_DOWNSTAIRS     0.9028    0.9952    0.9468       420\n",
            "           SITTING     0.8121    0.7658    0.7883       491\n",
            "          STANDING     0.8055    0.8327    0.8189       532\n",
            "            LAYING     1.0000    1.0000    1.0000       537\n",
            "\n",
            "          accuracy                         0.9131      2947\n",
            "         macro avg     0.9140    0.9151    0.9139      2947\n",
            "      weighted avg     0.9138    0.9131    0.9129      2947\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WKofyU-A3Z36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tvwFFKI13ZuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU-3: GRU version of RNN-3"
      ],
      "metadata": {
        "id": "5uK6upx13ZmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(n_steps, n_input))\n",
        "x = layers.GaussianNoise(stddev=0.1)(inputs)\n",
        "x = layers.GRU(128,return_sequences=True,kernel_regularizer=regularizers.l2(lambda_loss_amount),recurrent_dropout=0.2)(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.GRU(64,return_sequences=True,kernel_regularizer=regularizers.l2(lambda_loss_amount),recurrent_dropout=0.2)(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.GRU(32,kernel_regularizer=regularizers.l2(lambda_loss_amount),recurrent_dropout=0.2)(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "logits = layers.Dense(n_classes,kernel_regularizer=regularizers.l2(lambda_loss_amount),)(x)\n",
        "gru_model_3 = models.Model(inputs, logits)\n",
        "gru_model_3.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,clipnorm=1.0),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy')],\n",
        "    jit_compile=True\n",
        ")\n",
        "gru_model_3.summary()\n",
        "history = gru_model_3.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_ds,\n",
        "    callbacks=[cb_early, cb_lr]\n",
        ")\n",
        "loss, acc = gru_model_3.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "y_proba = gru_model_3.predict(test_ds)\n",
        "gru_3_y_pred  = np.argmax(y_proba, axis=1)\n",
        "y_true  = y_test\n",
        "print(metrics.classification_report(\n",
        "    y_true, gru_3_y_pred, target_names=LABELS, digits=4, zero_division=0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8mcvjImG3djt",
        "outputId": "fff78acc-7137-4a39-8adb-7d872d51d369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gaussian_noise_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m53,376\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m37,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_6 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m9,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gaussian_noise_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,376</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,678\u001b[0m (393.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,678</span> (393.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,678\u001b[0m (393.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,678</span> (393.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0025.\n",
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.5726 - loss: 1.4326 - val_accuracy: 0.8741 - val_loss: 0.6107 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0024975343971711255.\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.9070 - loss: 0.4989 - val_accuracy: 0.9237 - val_loss: 0.3895 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0024901473192924404.\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.9469 - loss: 0.3316 - val_accuracy: 0.9169 - val_loss: 0.3296 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.002477867919785497.\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.9470 - loss: 0.2829 - val_accuracy: 0.9233 - val_loss: 0.3025 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0024607446598302247.\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.9439 - loss: 0.2588 - val_accuracy: 0.9114 - val_loss: 0.3552 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0024388451171107944.\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.9392 - loss: 0.2595 - val_accuracy: 0.9345 - val_loss: 0.2873 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00241225571911737.\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.9538 - loss: 0.2192 - val_accuracy: 0.9199 - val_loss: 0.2952 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0023810814020562916.\n",
            "Epoch 8/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - accuracy: 0.9449 - loss: 0.2205 - val_accuracy: 0.9250 - val_loss: 0.2676 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0023454451967148075.\n",
            "Epoch 9/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.9531 - loss: 0.1934 - val_accuracy: 0.9376 - val_loss: 0.2557 - learning_rate: 0.0023\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.002305487742914768.\n",
            "Epoch 10/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.9506 - loss: 0.1901 - val_accuracy: 0.9284 - val_loss: 0.2709 - learning_rate: 0.0023\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.002261366734471497.\n",
            "Epoch 11/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.9469 - loss: 0.2070 - val_accuracy: 0.9023 - val_loss: 0.3227 - learning_rate: 0.0023\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0022132562968483487.\n",
            "Epoch 12/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - accuracy: 0.9487 - loss: 0.1978 - val_accuracy: 0.9104 - val_loss: 0.2992 - learning_rate: 0.0022\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 242ms/step - accuracy: 0.9078 - loss: 0.3220\n",
            "Test Loss: 0.2557, Test Accuracy: 0.9376\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 335ms/step\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "           WALKING     0.9734    0.9577    0.9654       496\n",
            "  WALKING_UPSTAIRS     0.9807    0.9724    0.9765       471\n",
            "WALKING_DOWNSTAIRS     0.9524    1.0000    0.9756       420\n",
            "           SITTING     0.8685    0.8208    0.8440       491\n",
            "          STANDING     0.8545    0.8835    0.8688       532\n",
            "            LAYING     1.0000    1.0000    1.0000       537\n",
            "\n",
            "          accuracy                         0.9376      2947\n",
            "         macro avg     0.9383    0.9390    0.9384      2947\n",
            "      weighted avg     0.9375    0.9376    0.9373      2947\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aS282cWe33Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xTKvhZNA326s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM-1: LSTM Model with the same structure and characteristics as RNN-1 model"
      ],
      "metadata": {
        "id": "YhfdNw_n32ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
        "x = layers.LSTM(128, return_sequences=True, kernel_regularizer=regularizers.l2(lambda_loss_amount))(inputs)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.LSTM(64, kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "logits = layers.Dense(n_classes, kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "lstm_model_1 = models.Model(inputs, logits)\n",
        "lstm_model_1.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy')],\n",
        "    jit_compile=True\n",
        ")\n",
        "lstm_model_1.summary()\n",
        "history = lstm_model_1.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_ds,\n",
        "    callbacks=[cb_early, cb_reduce]\n",
        ")\n",
        "loss, acc = lstm_model_1.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
        "y_proba = lstm_model_1.predict(test_ds)\n",
        "lstm_1_y_pred = np.argmax(y_proba, axis=1)\n",
        "y_true = y_test\n",
        "print(metrics.classification_report(\n",
        "    y_true, lstm_1_y_pred, target_names=LABELS, digits=4, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e_c-WURy38KX",
        "outputId": "c1f0dbcf-643d-406e-cc78-33e0bd138cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m70,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">70,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120,454\u001b[0m (470.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,454</span> (470.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120,454\u001b[0m (470.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,454</span> (470.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.4618 - loss: 1.4696 - val_accuracy: 0.5762 - val_loss: 1.0422 - learning_rate: 0.0025\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - accuracy: 0.6597 - loss: 0.8830 - val_accuracy: 0.7044 - val_loss: 0.8564 - learning_rate: 0.0025\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.6572 - loss: 0.8566 - val_accuracy: 0.6980 - val_loss: 0.8258 - learning_rate: 0.0025\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - accuracy: 0.7698 - loss: 0.6758 - val_accuracy: 0.7713 - val_loss: 0.6886 - learning_rate: 0.0025\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.8426 - loss: 0.5228 - val_accuracy: 0.7693 - val_loss: 0.7163 - learning_rate: 0.0025\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.8540 - loss: 0.5082 - val_accuracy: 0.8521 - val_loss: 0.5980 - learning_rate: 0.0025\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.9173 - loss: 0.3437 - val_accuracy: 0.8653 - val_loss: 0.4838 - learning_rate: 0.0025\n",
            "Epoch 8/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9349 - loss: 0.2893 - val_accuracy: 0.8568 - val_loss: 0.5202 - learning_rate: 0.0025\n",
            "Epoch 9/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - accuracy: 0.9130 - loss: 0.3800 - val_accuracy: 0.9057 - val_loss: 0.3650 - learning_rate: 0.0025\n",
            "Epoch 10/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - accuracy: 0.9422 - loss: 0.2523 - val_accuracy: 0.8860 - val_loss: 0.4519 - learning_rate: 0.0025\n",
            "Epoch 11/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.9040 - loss: 0.3791 - val_accuracy: 0.8422 - val_loss: 0.6085 - learning_rate: 0.0025\n",
            "Epoch 12/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - accuracy: 0.9310 - loss: 0.3052 - val_accuracy: 0.7838 - val_loss: 0.7007 - learning_rate: 0.0012\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - accuracy: 0.8634 - loss: 0.4180\n",
            "Test Loss: 0.3650, Test Accuracy: 0.9057\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 254ms/step\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "           WALKING     0.9381    0.9476    0.9428       496\n",
            "  WALKING_UPSTAIRS     0.9252    0.9193    0.9223       471\n",
            "WALKING_DOWNSTAIRS     0.9602    0.9762    0.9681       420\n",
            "           SITTING     0.7737    0.8493    0.8097       491\n",
            "          STANDING     0.8590    0.7556    0.8040       532\n",
            "            LAYING     0.9871    1.0000    0.9935       537\n",
            "\n",
            "          accuracy                         0.9057      2947\n",
            "         macro avg     0.9072    0.9080    0.9067      2947\n",
            "      weighted avg     0.9064    0.9057    0.9051      2947\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j6Nl3BM14S8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tiGmfj0b4S0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM-2- LSTM Version of RNN-2"
      ],
      "metadata": {
        "id": "O40JP1xb4SaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(n_steps, n_input))\n",
        "x = layers.LSTM(128,return_sequences=True,kernel_regularizer=regularizers.l2(lambda_loss_amount))(inputs)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.LSTM(64, kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "logits = layers.Dense(n_classes, kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "lstm_model_2 = models.Model(inputs, logits)\n",
        "lstm_model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy')],\n",
        "    jit_compile=True\n",
        ")\n",
        "lstm_model_2.summary()\n",
        "history = lstm_model_2.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_ds,\n",
        "    callbacks=[cb_early, cb_lr]\n",
        ")\n",
        "loss, acc = lstm_model_2.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
        "y_proba = lstm_model_2.predict(test_ds)\n",
        "lstm_2_y_pred = np.argmax(y_proba, axis=1)\n",
        "y_true = y_test\n",
        "print(metrics.classification_report(\n",
        "    y_true, lstm_2_y_pred, target_names=LABELS, digits=4, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fbT6avsm4bE4",
        "outputId": "d52c3173-5a22-412c-d122-9679634ee05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m70,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">70,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120,838\u001b[0m (472.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,838</span> (472.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120,838\u001b[0m (472.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,838</span> (472.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0025.\n",
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.5253 - loss: 1.5235 - val_accuracy: 0.7357 - val_loss: 0.9567 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0024975343971711255.\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.8407 - loss: 0.6800 - val_accuracy: 0.8683 - val_loss: 0.6365 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0024901473192924404.\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.9302 - loss: 0.3918 - val_accuracy: 0.8809 - val_loss: 0.5500 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.002477867919785497.\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.9377 - loss: 0.3207 - val_accuracy: 0.8962 - val_loss: 0.4880 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0024607446598302247.\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - accuracy: 0.9396 - loss: 0.3122 - val_accuracy: 0.8918 - val_loss: 0.4729 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0024388451171107944.\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - accuracy: 0.9501 - loss: 0.2495 - val_accuracy: 0.9060 - val_loss: 0.3756 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00241225571911737.\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - accuracy: 0.9508 - loss: 0.2332 - val_accuracy: 0.8582 - val_loss: 0.5307 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0023810814020562916.\n",
            "Epoch 8/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - accuracy: 0.9503 - loss: 0.2285 - val_accuracy: 0.9036 - val_loss: 0.3911 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0023454451967148075.\n",
            "Epoch 9/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - accuracy: 0.9485 - loss: 0.2158 - val_accuracy: 0.9226 - val_loss: 0.3862 - learning_rate: 0.0023\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - accuracy: 0.8847 - loss: 0.4116\n",
            "Test Loss: 0.3756, Test Accuracy: 0.9060\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 218ms/step\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "           WALKING     0.9533    0.9456    0.9494       496\n",
            "  WALKING_UPSTAIRS     0.8941    0.9682    0.9297       471\n",
            "WALKING_DOWNSTAIRS     0.9213    0.9476    0.9343       420\n",
            "           SITTING     0.8785    0.7067    0.7833       491\n",
            "          STANDING     0.8020    0.8985    0.8475       532\n",
            "            LAYING     1.0000    0.9721    0.9858       537\n",
            "\n",
            "          accuracy                         0.9060      2947\n",
            "         macro avg     0.9082    0.9064    0.9050      2947\n",
            "      weighted avg     0.9080    0.9060    0.9047      2947\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jeBR3JPX4zFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vvuZYbpr4zAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM-3: LSTM version of RNN-3"
      ],
      "metadata": {
        "id": "PFPPc3iJ4y0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(n_steps, n_input))\n",
        "x = layers.GaussianNoise(0.1)(inputs)\n",
        "x = layers.LSTM(128,return_sequences=True,kernel_regularizer=regularizers.l2(lambda_loss_amount),recurrent_dropout=0.2)(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.LSTM(64,return_sequences=True, kernel_regularizer=regularizers.l2(lambda_loss_amount),recurrent_dropout=0.2)(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.LSTM(32,kernel_regularizer=regularizers.l2(lambda_loss_amount),recurrent_dropout=0.2)(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "logits = layers.Dense(n_classes, kernel_regularizer=regularizers.l2(lambda_loss_amount))(x)\n",
        "lstm_model_3 = models.Model(inputs, logits)\n",
        "lstm_model_3.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,clipnorm=1.0),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy')],\n",
        "    jit_compile=True\n",
        ")\n",
        "lstm_model_3.summary()\n",
        "history = lstm_model_3.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_ds,\n",
        "    callbacks=[cb_early, cb_lr]\n",
        ")\n",
        "loss, acc = lstm_model_3.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
        "y_proba = lstm_model_3.predict(test_ds)\n",
        "lstm_3_y_pred = np.argmax(y_proba, axis=1)\n",
        "y_true = y_test\n",
        "print(metrics.classification_report(\n",
        "    y_true, lstm_3_y_pred, target_names=LABELS, digits=4, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "91ofpKa042nS",
        "outputId": "462f7fca-67b5-43fd-b2b7-99fdd272edf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gaussian_noise_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m70,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gaussian_noise_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">70,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m133,126\u001b[0m (520.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,126</span> (520.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133,126\u001b[0m (520.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,126</span> (520.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0025.\n",
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - accuracy: 0.5485 - loss: 1.6280 - val_accuracy: 0.8371 - val_loss: 0.7927 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0024975343971711255.\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.8939 - loss: 0.6566 - val_accuracy: 0.8962 - val_loss: 0.5817 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0024901473192924404.\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.9297 - loss: 0.4712 - val_accuracy: 0.8901 - val_loss: 0.5957 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.002477867919785497.\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.9402 - loss: 0.3779 - val_accuracy: 0.9030 - val_loss: 0.4976 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0024607446598302247.\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - accuracy: 0.9360 - loss: 0.3492 - val_accuracy: 0.9067 - val_loss: 0.4763 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0024388451171107944.\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.9387 - loss: 0.3058 - val_accuracy: 0.9002 - val_loss: 0.4304 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00241225571911737.\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.9461 - loss: 0.2756 - val_accuracy: 0.8904 - val_loss: 0.4456 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0023810814020562916.\n",
            "Epoch 8/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.9471 - loss: 0.2686 - val_accuracy: 0.9196 - val_loss: 0.3514 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0023454451967148075.\n",
            "Epoch 9/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - accuracy: 0.9476 - loss: 0.2552 - val_accuracy: 0.9091 - val_loss: 0.3440 - learning_rate: 0.0023\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.002305487742914768.\n",
            "Epoch 10/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.9415 - loss: 0.2425 - val_accuracy: 0.9101 - val_loss: 0.4186 - learning_rate: 0.0023\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.002261366734471497.\n",
            "Epoch 11/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9459 - loss: 0.2308 - val_accuracy: 0.8945 - val_loss: 0.5007 - learning_rate: 0.0023\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0022132562968483487.\n",
            "Epoch 12/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.9460 - loss: 0.2261 - val_accuracy: 0.9019 - val_loss: 0.5342 - learning_rate: 0.0022\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - accuracy: 0.8700 - loss: 0.4078\n",
            "Test Loss: 0.3440, Test Accuracy: 0.9091\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 292ms/step\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "           WALKING     0.9498    0.9919    0.9704       496\n",
            "  WALKING_UPSTAIRS     0.9290    0.9448    0.9368       471\n",
            "WALKING_DOWNSTAIRS     0.9736    0.9643    0.9689       420\n",
            "           SITTING     0.7864    0.8024    0.7944       491\n",
            "          STANDING     0.8246    0.7951    0.8096       532\n",
            "            LAYING     1.0000    0.9683    0.9839       537\n",
            "\n",
            "          accuracy                         0.9091      2947\n",
            "         macro avg     0.9106    0.9112    0.9107      2947\n",
            "      weighted avg     0.9092    0.9091    0.9089      2947\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u33jwBZWBpCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Sk1mu1TBo-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_=[\"rnn_model_1\",\"rnn_model_2\",\"rnn_model_3\",\"gru_model_1\",\"gru_model_2\",\"gru_model_3\",\"lstm_model_1\",\"lstm_model_2\",\"lstm_model_3\"]\n",
        "predictions_=[rnn_1_y_pred,rnn_2_y_pred,rnn_3_y_pred,gru_1_y_pred,gru_2_y_pred,gru_3_y_pred,lstm_1_y_pred,lstm_2_y_pred,lstm_3_y_pred]\n",
        "\n",
        "results=[]\n",
        "for model_name,model_prediction in zip(models_,predictions_):\n",
        "  results.append(\n",
        "      {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy_score(y_true, model_prediction),\n",
        "        'Precision': precision_score(y_true, model_prediction, average='macro'),\n",
        "        'Recall': recall_score(y_true, model_prediction, average='macro'),\n",
        "        'F1-Score': f1_score(y_true, model_prediction, average='macro')\n",
        "    }\n",
        "  )\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "print(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63sCAX64Bpgh",
        "outputId": "69142cc4-bcf1-4491-a995-727390efe147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Model  Accuracy  Precision    Recall  F1-Score\n",
            "0   rnn_model_1  0.718697   0.743337  0.708125  0.685735\n",
            "1   rnn_model_2  0.652189   0.671801  0.640137  0.644871\n",
            "2   rnn_model_3  0.434001   0.378251  0.425340  0.345199\n",
            "3   gru_model_1  0.894808   0.902739  0.896195  0.894182\n",
            "4   gru_model_2  0.913132   0.913964  0.915095  0.913898\n",
            "5   gru_model_3  0.937564   0.938258  0.939049  0.938391\n",
            "6  lstm_model_1  0.905667   0.907214  0.908003  0.906740\n",
            "7  lstm_model_2  0.906006   0.908193  0.906437  0.904996\n",
            "8  lstm_model_3  0.909060   0.910562  0.911153  0.910666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_results.set_index('Model', inplace=True)\n",
        "\n",
        "# Plot bar charts for each metric\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "for idx, metric in enumerate(metrics, 1):\n",
        "    plt.subplot(2, 2, idx)\n",
        "    df_results[metric].plot(kind='bar')\n",
        "    plt.title(metric)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(metric)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "pSS_XGc2IOWf",
        "outputId": "547570af-7d38-4ce7-e56b-d7271ce3ecc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}